{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#add necessary libraries\n",
    "import networkx as nx #library supporting networks\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "from scipy import optimize\n",
    "import pysal as ps\n",
    "from zipfile import ZipFile\n",
    "from StringIO import StringIO\n",
    "#make sure plots are embedded into the notebook\n",
    "%pylab inline \n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            fips      gdp\n",
      "state                    \n",
      "Alabama     1000   199440\n",
      "Alaska      2000    57080\n",
      "Arizona     4000   284156\n",
      "Arkansas    5000   121395\n",
      "California  6000  2311616\n",
      "Index([u'fips', u'gdp'], dtype='object')\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# load state gdp data (2014)\n",
    "gdp = pd.read_csv('bea_gdp_by_state_in_millions.csv', header = 0, names=['fips', 'state', 'gdp'], index_col=['state'])\n",
    "print gdp.head()\n",
    "print gdp.columns\n",
    "print len(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id abbrev      capital   latitude   longitude  population\n",
      "state                                                                \n",
      "Alabama      1     AL   Montgomery  32.380120  -86.300629      205764\n",
      "Alaska       2     AK       Juneau  58.299740 -134.406794       31275\n",
      "Arizona      4     AZ      Phoenix  33.448260 -112.075774     1445632\n",
      "Arkansas     5     AR  Little Rock  34.748655  -92.274494      193524\n",
      "California   6     CA   Sacramento  38.579065 -121.491014      466488\n",
      "Index([u'id', u'abbrev', u'capital', u'latitude', u'longitude', u'population'], dtype='object')\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# load state capitals\n",
    "caps = pd.read_csv('Capitals.csv', header = 0, index_col=['state'])\n",
    "print caps.head()\n",
    "print caps.columns\n",
    "print len(caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            STATEFP  POPULATION   LATITUDE   LONGITUDE\n",
      "STNAME                                                \n",
      "Alabama           1     4779736  33.008097  -86.756826\n",
      "Alaska            2      710231  61.399882 -148.873973\n",
      "Arizona           4     6392017  33.368266 -111.864310\n",
      "Arkansas          5     2915918  35.142580  -92.655243\n",
      "California        6    37253956  35.463595 -119.325359\n",
      "Index([u'STATEFP', u'POPULATION', u'LATITUDE', u'LONGITUDE'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load state population centers\n",
    "popcenter = pd.read_csv('CenPop2010_Mean_ST.txt', index_col=['STNAME'])\n",
    "print popcenter.head()\n",
    "print popcenter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "Index([u'State_Sales', u'Avg_Local_Sales', u'Combined_Sales',\n",
      "       u'Max_Local_Sales', u'Property', u'Income_Low', u'Income_High',\n",
      "       u'Mature_Firm_HQ', u'New_Firm_HQ'],\n",
      "      dtype='object')\n",
      "            State_Sales  Avg_Local_Sales  Combined_Sales  Max_Local_Sales  \\\n",
      "Alabama           0.040           0.0491          0.0891            0.070   \n",
      "Alaska              NaN           0.0176          0.0176            0.075   \n",
      "Arizona           0.056           0.0257          0.0817            0.053   \n",
      "Arkansas          0.065           0.0276          0.0926            0.055   \n",
      "California        0.075           0.0094          0.0844            0.025   \n",
      "\n",
      "            Property  Income_Low  Income_High  Mature_Firm_HQ  New_Firm_HQ  \n",
      "Alabama       0.0033      0.0200       0.0500           0.130        0.133  \n",
      "Alaska        0.0104         NaN          NaN           0.112        0.124  \n",
      "Arizona       0.0072      0.0259       0.0454           0.124        0.170  \n",
      "Arkansas      0.0052      0.0090       0.0690           0.136        0.089  \n",
      "California    0.0074      0.0100       0.1230           0.168        0.209  \n"
     ]
    }
   ],
   "source": [
    "# load state tax rates (all types)\n",
    "tax = pd.read_excel('Taxes rates by state.xlsx', index_col=['State'])\n",
    "print len(tax)\n",
    "\n",
    "# clean col names to make easier to work with\n",
    "tax.columns = ['State_Sales', 'Avg_Local_Sales', 'Combined_Sales', 'Max_Local_Sales'\n",
    "               , 'Property', 'Income_Low', 'Income_High', 'Mature_Firm_HQ', 'New_Firm_HQ']\n",
    "print tax.columns\n",
    "#print tax.head()\n",
    "\n",
    "# clean index names\n",
    "tax.index =  [state.replace(\"\\\"\", \"\") for state in tax.index]\n",
    "#print tax.index\n",
    "\n",
    "# convert percentages to floats\n",
    "tax['New_Firm_HQ'] = tax['New_Firm_HQ'].replace('%','',regex=True).astype('float')/100\n",
    "tax['Mature_Firm_HQ'] = tax['Mature_Firm_HQ'].replace('%','',regex=True).astype('float')/100\n",
    "\n",
    "print tax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'AFFGEOID',    u'ALAND',   u'AWATER',    u'GEOID',     u'LSAD',\n",
      "           u'NAME',  u'STATEFP',  u'STATENS',   u'STUSPS', u'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# This is only for the shapes that will be used by PySAL to \n",
    "# build the spatial weights matrix\n",
    "data = gpd.read_file('cb_2014_us_state_5m/cb_2014_us_state_5m.shp')\n",
    "psGeom = ps.open('cb_2014_us_state_5m/cb_2014_us_state_5m.shp', 'r')\n",
    "\n",
    "print data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build spatial weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Rook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: there are 7 disconnected observations\n",
      "Island ids:  [u'Puerto Rico', u'Commonwealth of the Northern Mariana Islands', u'Alaska', u'Hawaii', u'United States Virgin Islands', u'American Samoa', u'Guam']\n",
      "WARNING:  Puerto Rico  is an island (no neighbors)\n",
      "WARNING:  Commonwealth of the Northern Mariana Islands  is an island (no neighbors)\n",
      "WARNING:  Alaska  is an island (no neighbors)\n",
      "WARNING:  Hawaii  is an island (no neighbors)\n",
      "WARNING:  United States Virgin Islands  is an island (no neighbors)\n",
      "WARNING:  American Samoa  is an island (no neighbors)\n",
      "WARNING:  Guam  is an island (no neighbors)\n"
     ]
    }
   ],
   "source": [
    "# We are building the spatial weight matrix and using the \n",
    "# state names as IDs of the matrix.\n",
    "\n",
    "R = ps.buildContiguity(psGeom, criterion='rook', ids=data['NAME'].values.tolist())\n",
    "R.transform = 'R' # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for (loc, neighbors) in R:\n",
    "    #print loc, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Queen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: there are 7 disconnected observations\n",
      "Island ids:  [u'Puerto Rico', u'Commonwealth of the Northern Mariana Islands', u'Alaska', u'Hawaii', u'United States Virgin Islands', u'American Samoa', u'Guam']\n",
      "WARNING:  Puerto Rico  is an island (no neighbors)\n",
      "WARNING:  Commonwealth of the Northern Mariana Islands  is an island (no neighbors)\n",
      "WARNING:  Alaska  is an island (no neighbors)\n",
      "WARNING:  Hawaii  is an island (no neighbors)\n",
      "WARNING:  United States Virgin Islands  is an island (no neighbors)\n",
      "WARNING:  American Samoa  is an island (no neighbors)\n",
      "WARNING:  Guam  is an island (no neighbors)\n"
     ]
    }
   ],
   "source": [
    "# We are building the spatial weight matrix and using the \n",
    "# state names as IDs of the matrix. Noted that we\n",
    "# running a 'queen', shared vertices, neighborhood test.\n",
    "\n",
    "Q = ps.buildContiguity(psGeom, criterion='queen', ids=data['NAME'].values.tolist())\n",
    "Q.transform = 'R' # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for (loc, neighbors) in Q:\n",
    "    #print loc, neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Distance-weighted by state capitals (50 by 50 matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id abbrev         capital   latitude   longitude  population\n",
      "state                                                                       \n",
      "Alabama          1     AL      Montgomery  32.380120  -86.300629      205764\n",
      "Alaska           2     AK          Juneau  58.299740 -134.406794       31275\n",
      "Arizona          4     AZ         Phoenix  33.448260 -112.075774     1445632\n",
      "Arkansas         5     AR     Little Rock  34.748655  -92.274494      193524\n",
      "California       6     CA      Sacramento  38.579065 -121.491014      466488\n",
      "Colorado         8     CO          Denver  39.740010 -104.992259      600158\n",
      "Connecticut      9     CT        Hartford  41.763325  -72.674069      124775\n",
      "Delaware        10     DE           Dover  39.158035  -75.524734       36047\n",
      "Florida         12     FL     Tallahassee  30.439775  -84.280649      181376\n",
      "Georgia         13     GA         Atlanta  33.748315  -84.391109      420003\n",
      "Hawaii          15     HI        Honolulu  21.304770 -157.857614      337256\n",
      "Idaho           16     ID           Boise  43.606980 -116.193409      205671\n",
      "Illinois        17     IL     Springfield  39.801055  -89.643604      116250\n",
      "Indiana         18     IN    Indianapolis  39.766910  -86.149964      820445\n",
      "Iowa            19     IA      Des Moines  41.589790  -93.615659      203433\n",
      "Kansas          20     KS          Topeka  39.049285  -95.671184      127473\n",
      "Kentucky        21     KY       Frankfort  38.195070  -84.878694       25527\n",
      "Louisiana       22     LA     Baton Rouge  30.443345  -91.186994      229493\n",
      "Maine           23     ME         Augusta  44.318036  -69.776218       19136\n",
      "Maryland        24     MD       Annapolis  38.976700  -76.489934       38394\n",
      "Massachusetts   25     MA          Boston  42.358635  -71.056699      617594\n",
      "Michigan        26     MI         Lansing  42.731940  -84.552249      114297\n",
      "Minnesota       27     MN      Saint Paul  44.943829  -93.093326      285068\n",
      "Mississippi     28     MS         Jackson  32.298690  -90.180489      173514\n",
      "Missouri        29     MO  Jefferson City  38.577515  -92.177839       43079\n",
      "Montana         30     MT          Helana  46.589760 -112.021202       28190\n",
      "Nebraska        31     NE         Lincoln  40.813620  -96.707739      258379\n",
      "Nevada          32     NV     Carson City  39.164885 -119.766999       55274\n",
      "New Hampshire   33     NH         Concord  43.207250  -71.536604       42695\n",
      "New Jersey      34     NJ         Trenton  40.217875  -74.759404       84913\n",
      "New Mexico      35     NM        Santa Fe  35.691543 -105.937406       67947\n",
      "New York        36     NY          Albany  42.651445  -73.755254       97856\n",
      "North Carolina  37     NC         Raleigh  35.785510  -78.642669      403892\n",
      "North Dakota    38     ND        Bismarck  46.805372 -100.779334       61272\n",
      "Ohio            39     OH        Columbus  39.961960  -83.002984      787033\n",
      "Oklahoma        40     OK   Oklahoma City  35.472015  -97.520354      579999\n",
      "Oregon          41     OR           Salem  44.933260 -123.043814      154637\n",
      "Pennsylvania    42     PA      Harrisburg  40.259865  -76.882230       49528\n",
      "Rhode Island    44     RI      Providence  41.823875  -71.411994      178042\n",
      "South Carolina  45     SC        Columbia  33.998550  -81.045249      129272\n",
      "South Dakota    46     SD          Pierre  44.368924 -100.350158       13646\n",
      "Tennessee       47     TN       Nashville  36.167783  -86.778365      601222\n",
      "Texas           48     TX          Austin  30.267605  -97.742984      790390\n",
      "Utah            49     UT  Salt Lake City  40.759505 -111.888229      186440\n",
      "Vermont         50     VT      Montpelier  44.260299  -72.576264        7855\n",
      "Virginia        51     VA        Richmond  37.540700  -77.433654      204214\n",
      "Washington      53     WA         Olympia  47.039231 -122.891366       46478\n",
      "West Virginia   54     WV      Charleston  38.350195  -81.638989       51400\n",
      "Wisconsin       55     WI         Madison  43.072950  -89.386694      233209\n",
      "Wyoming         56     WY        Cheyenne  41.134815 -104.821544       59466\n"
     ]
    }
   ],
   "source": [
    "print caps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Distance-weighted by population centers (50 by 50 matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Gravity model (???) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate spatial auto-correlations for tax rates (each type)\n",
    "### Morans I (see lab9_sa from NYU Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Template\n",
    "\n",
    "# Y is the normalized list of values\n",
    "\n",
    "# Y = data['percent'].values\n",
    "# Y = (Y-Y.mean())/Y.std() # <<<---- normalization\n",
    "\n",
    "\n",
    "# W is the standardized dict. of all the weights. This can be \n",
    "# done by specifying 'R' as the matrix transformation. All the weights\n",
    "# should add up to 1.\n",
    "\n",
    "# W.transform = 'R'\n",
    "\n",
    "\n",
    "# Execute the Moran's I calculation\n",
    "\n",
    "# mi = ps.Moran(Y, W)\n",
    "\n",
    "# This is the Moran's I value, that would tell us whether tax rates\n",
    "# among states are clustered, or not.\n",
    "\n",
    "# mi.I\n",
    "\n",
    "# Check the p-value of the calculation. This has to be < 0.05 for our\n",
    "# calculation to be statistically significant.\n",
    "\n",
    "# mi.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Rook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
