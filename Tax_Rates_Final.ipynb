{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IP Notebook for ADS Fall 2015 Networks Project on US State Tax Rates\n",
    "## Jiheng, Linda, Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# add necessary libraries\n",
    "import networkx as nx #library supporting networks\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "from scipy import optimize\n",
    "import pysal as ps\n",
    "#from zipfile import ZipFile\n",
    "#from StringIO import StringIO\n",
    "# make sure plots are embedded into the notebook\n",
    "%pylab inline \n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            fips      gdp\n",
      "state                    \n",
      "Alabama     1000   199440\n",
      "Alaska      2000    57080\n",
      "Arizona     4000   284156\n",
      "Arkansas    5000   121395\n",
      "California  6000  2311616\n",
      "Index([u'fips', u'gdp'], dtype='object')\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# load state gdp data (2014)\n",
    "gdp = pd.read_csv('bea_gdp_by_state_in_millions.csv', header = 0, names=['fips', 'state', 'gdp'], index_col=['state'])\n",
    "print gdp.head()\n",
    "print gdp.columns\n",
    "print len(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id abbrev      capital   latitude   longitude  population\n",
      "state                                                                \n",
      "Alabama      1     AL   Montgomery  32.380120  -86.300629      205764\n",
      "Alaska       2     AK       Juneau  58.299740 -134.406794       31275\n",
      "Arizona      4     AZ      Phoenix  33.448260 -112.075774     1445632\n",
      "Arkansas     5     AR  Little Rock  34.748655  -92.274494      193524\n",
      "California   6     CA   Sacramento  38.579065 -121.491014      466488\n",
      "Index([u'id', u'abbrev', u'capital', u'latitude', u'longitude', u'population'], dtype='object')\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# load state capitals\n",
    "caps = pd.read_csv('Capitals.csv', header = 0, index_col=['state'])\n",
    "print caps.head()\n",
    "print caps.columns\n",
    "print len(caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            STATEFP  POPULATION   LATITUDE   LONGITUDE\n",
      "STNAME                                                \n",
      "Alabama           1     4779736  33.008097  -86.756826\n",
      "Alaska            2      710231  61.399882 -148.873973\n",
      "Arizona           4     6392017  33.368266 -111.864310\n",
      "Arkansas          5     2915918  35.142580  -92.655243\n",
      "California        6    37253956  35.463595 -119.325359\n",
      "Index([u'STATEFP', u'POPULATION', u'LATITUDE', u'LONGITUDE'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load state population centers\n",
    "popcenter = pd.read_csv('CenPop2010_Mean_ST.txt', index_col=['STNAME'])\n",
    "print popcenter.head()\n",
    "print popcenter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "Index([u'State_Sales', u'Avg_Local_Sales', u'Combined_Sales',\n",
      "       u'Max_Local_Sales', u'Property', u'Income_Low', u'Income_High',\n",
      "       u'Mature_Firm_HQ', u'New_Firm_HQ'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load state tax rates (all types)\n",
    "tax = pd.read_excel('Taxes rates by state.xlsx', index_col=['State'])\n",
    "print len(tax)\n",
    "\n",
    "# clean col names to make easier to work with\n",
    "tax.columns = ['State_Sales', 'Avg_Local_Sales', 'Combined_Sales', 'Max_Local_Sales'\n",
    "               , 'Property', 'Income_Low', 'Income_High', 'Mature_Firm_HQ', 'New_Firm_HQ']\n",
    "print tax.columns\n",
    "#print tax.head()\n",
    "\n",
    "# clean index names\n",
    "tax.index =  [state.replace(\"\\\"\", \"\").strip() for state in tax.index]\n",
    "#print tax.index\n",
    "\n",
    "# convert percentages to floats\n",
    "tax['New_Firm_HQ'] = tax['New_Firm_HQ'].replace('%','',regex=True).astype('float')/100\n",
    "tax['Mature_Firm_HQ'] = tax['Mature_Firm_HQ'].replace('%','',regex=True).astype('float')/100\n",
    "\n",
    "tax = tax.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNONGRAVITY MODELS\\nCombined_Sales: highest spatial auto-correlation based on rook/queen\\n    you can only travel so far to buy stuff\\nProperty: low spatial auto-corr (rook > queen marginally)\\n    since tied to land\\n\\nPOTENTIAL FOR GRAVITY MODEL\\nIncome-Low vs. Income-High: lower for low income than for high income since richer people are more mobile\\n    also, look at gravity model here\\nMature_Firm_HQ: high spatial auto-correlation\\n    also gravity model\\nNew_Firm_HQ: even higher spatial auto-corr than mature\\n    new firms are more mobile than mature firms)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What makes intuitive sense\n",
    "\n",
    "'''\n",
    "NONGRAVITY MODELS\n",
    "Combined_Sales: highest spatial auto-correlation based on rook/queen\n",
    "    you can only travel so far to buy stuff\n",
    "Property: low spatial auto-corr (rook > queen marginally)\n",
    "    since tied to land\n",
    "\n",
    "POTENTIAL FOR GRAVITY MODEL\n",
    "Income-Low vs. Income-High: lower for low income than for high income since richer people are more mobile\n",
    "    also, look at gravity model here\n",
    "Mature_Firm_HQ: high spatial auto-correlation\n",
    "    also gravity model\n",
    "New_Firm_HQ: even higher spatial auto-corr than mature\n",
    "    new firms are more mobile than mature firms)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'AFFGEOID',    u'ALAND',   u'AWATER',    u'GEOID',     u'LSAD',\n",
      "           u'NAME',  u'STATEFP',  u'STATENS',   u'STUSPS', u'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# This is only for the shapes that will be used by PySAL to \n",
    "# build the spatial weights matrix\n",
    "data = gpd.read_file('cb_2014_us_state_5m/cb_2014_us_state_5m.shp')\n",
    "psGeom = ps.open('cb_2014_us_state_5m/cb_2014_us_state_5m.shp', 'r')\n",
    "\n",
    "print data.columns\n",
    "\n",
    "# clean state names\n",
    "data['NAME'] = [statename.strip() for statename in data['NAME']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build spatial weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Rook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: there are 7 disconnected observations\n",
      "Island ids:  [u'Puerto Rico', u'Commonwealth of the Northern Mariana Islands', u'Alaska', u'Hawaii', u'United States Virgin Islands', u'American Samoa', u'Guam']\n",
      "WARNING:  Puerto Rico  is an island (no neighbors)\n",
      "WARNING:  Commonwealth of the Northern Mariana Islands  is an island (no neighbors)\n",
      "WARNING:  Alaska  is an island (no neighbors)\n",
      "WARNING:  Hawaii  is an island (no neighbors)\n",
      "WARNING:  United States Virgin Islands  is an island (no neighbors)\n",
      "WARNING:  American Samoa  is an island (no neighbors)\n",
      "WARNING:  Guam  is an island (no neighbors)\n"
     ]
    }
   ],
   "source": [
    "# We are building the spatial weight matrix and using the \n",
    "# state names as IDs of the matrix.\n",
    "\n",
    "R = ps.buildContiguity(psGeom, criterion='rook', ids=data['NAME'].values.tolist())\n",
    "R.transform = 'R' # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for (loc, neighbors) in R:\n",
    " #   print loc, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pysal.weights.weights.W'>\n"
     ]
    }
   ],
   "source": [
    "print type(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Queen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: there are 7 disconnected observations\n",
      "Island ids:  [u'Puerto Rico', u'Commonwealth of the Northern Mariana Islands', u'Alaska', u'Hawaii', u'United States Virgin Islands', u'American Samoa', u'Guam']\n",
      "WARNING:  Puerto Rico  is an island (no neighbors)\n",
      "WARNING:  Commonwealth of the Northern Mariana Islands  is an island (no neighbors)\n",
      "WARNING:  Alaska  is an island (no neighbors)\n",
      "WARNING:  Hawaii  is an island (no neighbors)\n",
      "WARNING:  United States Virgin Islands  is an island (no neighbors)\n",
      "WARNING:  American Samoa  is an island (no neighbors)\n",
      "WARNING:  Guam  is an island (no neighbors)\n"
     ]
    }
   ],
   "source": [
    "# We are building the spatial weight matrix and using the \n",
    "# state names as IDs of the matrix. Noted that we\n",
    "# running a 'queen', shared vertices, neighborhood test.\n",
    "\n",
    "Q = ps.buildContiguity(psGeom, criterion='queen', ids=data['NAME'].values.tolist())\n",
    "Q.transform = 'R' # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of States with Data:  51\n",
      "\n",
      "WARNING: there are 2 disconnected observations\n",
      "Island ids:  [u'Alaska', u'Hawaii']\n",
      "WARNING:  Alaska  is an island (no neighbors)\n",
      "WARNING:  Hawaii  is an island (no neighbors)\n",
      "\n",
      "Queen:  -0.148484732177 0.084\n"
     ]
    }
   ],
   "source": [
    "# 1. get data where tax rate is provided\n",
    "print 'Number of States with Data: ', len(tax)\n",
    "print\n",
    "ids = tax.index.values.tolist()\n",
    "#print ids # list of states with this tax rate provided\n",
    "\n",
    "# 3. subset queen spatial weights matrix to only those states\n",
    "Q_Sales = ps.w_subset(Q, ids)\n",
    "Q_Sales.transform = 'R' # normalize\n",
    "#print Q_Property.id_order\n",
    "\n",
    "# 4. get and normalize tax rate values (dependent variable)\n",
    "Y = tax['State_Sales'].values\n",
    "Y = (Y-Y.mean())/Y.std() # <<<---- normalization\n",
    "\n",
    "# 5. calculate Moran's statistics for spatial auto-corr. with ROOK and QUEEN\n",
    "mi_Q = ps.Moran(Y, Q_Sales)\n",
    "print\n",
    "print 'Queen: ', mi_Q.I, mi_Q.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Distance-weighted by population centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get latlong points\n",
    "points = [(popcenter['LATITUDE'][i], popcenter['LONGITUDE'][i]) for i in popcenter.index.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get dict. keys for state names\n",
    "ids = tax.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# custom latlong dist calc function\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def geodist(lon1,lat1,lon2,lat2):\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)  \n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "    R = 6373.0\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define custom spatial weight matrix by first defining all states as neighbors\n",
    "neighbors = {}\n",
    "for state in ids:\n",
    "    neighbors[state] = ids    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define weights\n",
    "weights = {}\n",
    "\n",
    "#count the states\n",
    "i = 0\n",
    "\n",
    "for state in ids:\n",
    "    result=[]\n",
    "    for a in xrange(0, 51):\n",
    "        if i == a: # self-weight = 0\n",
    "            b = 0\n",
    "        else:\n",
    "            b = 1.0/ geodist(points[i][0],points[i][1],points[a][0],points[a][1])\n",
    "        result.append(b)\n",
    "    weights[state] = result\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build matrix\n",
    "w = ps.W(neighbors, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "w.transform = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance:  -1.0573733028e-34 0.303\n"
     ]
    }
   ],
   "source": [
    "# 1. subset distance weighted spatial weights matrix to only those states\n",
    "# this step is actually not nec., from legacy formatting\n",
    "D_Income = ps.w_subset(w, ids)\n",
    "D_Income.transform = 'R' # normalize again\n",
    "\n",
    "# 2. get and normalize tax rate values (dependent variable)\n",
    "Y = tax['Income_High'].values\n",
    "Y = (Y-Y.mean())/Y.std() # <<<---- normalization\n",
    "\n",
    "# 3. calculate Moran's statistics for spatial auto-corr. with DISTANCE\n",
    "mi_D = ps.Moran(Y, D_Income)\n",
    "print\n",
    "print 'Distance: ', mi_D.I, mi_D.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distance:  0.0 0.083\n"
     ]
    }
   ],
   "source": [
    "# 1. subset distance weighted spatial weights matrix to only those states\n",
    "# this step is actually not nec., from legacy formatting\n",
    "D_Income = ps.w_subset(w, ids)\n",
    "D_Income.transform = 'R' # normalize again\n",
    "\n",
    "# 2. get and normalize tax rate values (dependent variable)\n",
    "Y = tax['Income_Low'].values\n",
    "Y = (Y-Y.mean())/Y.std() # <<<---- normalization\n",
    "\n",
    "# 3. calculate Moran's statistics for spatial auto-corr. with DISTANCE\n",
    "mi_D = ps.Moran(Y, D_Income)\n",
    "print\n",
    "print 'Distance: ', mi_D.I, mi_D.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Gravity model (with local normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# buid spatial weight matrix again\n",
    "weightsHQ = {}\n",
    "\n",
    "# count the states\n",
    "i = 0\n",
    "\n",
    "for state in ids:\n",
    "    result=[]\n",
    "    for a in xrange(0, 51):\n",
    "        dest = ids[a]\n",
    "        if i == a:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = 1.0 * gdp['gdp'][dest]/ geodist(points[i][0],points[i][1],points[a][0],points[a][1]) \n",
    "        result.append(b)\n",
    "    weightsHQ[state] = result\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = ps.W(neighbors, weightsHQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g.transform = \"R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HQ Tax Gravity:  -3.02106657943e-34 0.028\n"
     ]
    }
   ],
   "source": [
    "# 1. subset spatial weights matrix to only those states\n",
    "G_HQTax = ps.w_subset(g, ids)\n",
    "G_HQTax.transform = 'R' # normalize\n",
    "\n",
    "# 2. get and normalize tax rate values (dependent variable)\n",
    "Y = tax['New_Firm_HQ'].values\n",
    "Y = (Y-Y.mean())/Y.std() # <<<---- normalization\n",
    "\n",
    "# 3. calculate Moran's statistics for spatial auto-corr. with GRAVITY (MASS AND DISTANCE)\n",
    "mi_G = ps.Moran(Y, G_HQTax)\n",
    "print\n",
    "print 'HQ Tax Gravity: ', mi_G.I, mi_G.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HQ Tax Gravity:  2.41685326354e-34 0.157\n"
     ]
    }
   ],
   "source": [
    "# 1. subset spatial weights matrix to only those states\n",
    "G_HQTax = ps.w_subset(g, ids)\n",
    "G_HQTax.transform = 'R' # normalize\n",
    "\n",
    "# 2. get and normalize tax rate values (dependent variable)\n",
    "Y = tax['Mature_Firm_HQ'].values\n",
    "Y = (Y-Y.mean())/Y.std() # <<<---- normalization\n",
    "\n",
    "# 3. calculate Moran's statistics for spatial auto-corr. with GRAVITY (MASS AND DISTANCE)\n",
    "mi_G = ps.Moran(Y, G_HQTax)\n",
    "print\n",
    "print 'HQ Tax Gravity: ', mi_G.I, mi_G.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
